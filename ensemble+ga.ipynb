{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Importing three component ensembles\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#importing SVC for second-step classification\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutationRate = 0.001\n",
    "crossOverRate = 0.06\n",
    "iterations = 10\n",
    "poolSize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions for genetic algorithms\n",
    "\n",
    "def roulette(fitnessArray):\n",
    "    index = 0\n",
    "    cumalativeFitness = 0.0\n",
    "    r = random.random()\n",
    "    \n",
    "    for i in range(len(fitnessArray)):\n",
    "        cumalativeFitness += fitnessArray[i]\n",
    "        if cumalativeFitness > r:\n",
    "            return i\n",
    "\n",
    "\n",
    "def selectFittest(fitness, rankedPool):\n",
    "    while True:\n",
    "        idx1 = roulette(fitness)\n",
    "        idx2 = roulette(fitness)\n",
    "        \n",
    "        if idx1 is None or idx2 is None:\n",
    "            continue\n",
    "        elif idx1==idx2:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return rankedPool[idx1], rankedPool[idx2]\n",
    "\n",
    "def crossover(chromosome1, chromosome2):\n",
    "    randomSplitPoint = random.randint(1, len(chromosome1))\n",
    "    return np.concatenate((chromosome1[:randomSplitPoint],chromosome2[randomSplitPoint:])), np.concatenate((chromosome2[:randomSplitPoint],chromosome1[randomSplitPoint:]))\n",
    "\n",
    "\n",
    "def mutate(chromosome):\n",
    "\n",
    "    mutatedChrom = []\n",
    "    for ch in chromosome:\n",
    "        if random.random()<mutationRate:\n",
    "            if ch==1:\n",
    "                mutatedChrom.append(0)\n",
    "            else:\n",
    "                mutatedChrom.append(1)\n",
    "        else:\n",
    "            mutatedChrom.append(ch)\n",
    "    return mutatedChrom\n",
    "    \n",
    "def breed(chrome1, chrome2):\n",
    "    if random.random()<crossOverRate:\n",
    "        newChrome1, newChrome2 = crossover(chrome1, chrome2)\n",
    "    else:\n",
    "        newChrome1 = chrome1\n",
    "        newChrome2 = chrome2\n",
    "        \n",
    "    newChrome1 = mutate(newChrome1)\n",
    "    newChrome2 = mutate(newChrome2)\n",
    "    \n",
    "    return newChrome1, newChrome2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankPop(pool, X, y, classifier,fitnessFunction):\n",
    "    scores = []\n",
    "    for chromosome in pool:\n",
    "        classifier = RandomForestClassifier()\n",
    "        chosen_idx = [idx for gene, idx in zip(chromosome, range(X.shape[1])) if gene==1]\n",
    "        if len(chosen_idx)==0:\n",
    "            continue\n",
    "        chosenX = X.iloc[:, chosen_idx]\n",
    "        #performing leave-one out validation for instances less than 100\n",
    "        #and 10 fold validation for others\n",
    "        npoints = X.shape[0]\n",
    "   \n",
    "        if npoints <= 100:\n",
    "            kf = KFold(n_splits = npoints)\n",
    "        else:\n",
    "            kf = KFold(n_splits = 10)\n",
    "        \n",
    "        kf.get_n_splits(X)\n",
    "        classifier.fit(chosenX, y)\n",
    "        train_X = []\n",
    "        train_Y  = []\n",
    "        prediction   = []\n",
    "        predict_prob = []\n",
    "        chosenX = np.array(chosenX)\n",
    "        Y = np.array(y)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            classifier = RandomForestClassifier()\n",
    "            for i in train_index:\n",
    "                train_X.append(chosenX[i])\n",
    "                train_Y.append(Y[i])\n",
    "\n",
    "            classifier.fit(train_X, train_Y)\n",
    "            for j in test_index:\n",
    "                prediction.append(classifier.predict([chosenX[j]])[0])\n",
    "                predict_prob.append(classifier.predict_proba([chosenX[j]])[0][1])\n",
    "            train_X  = []\n",
    "            train_Y  = []\n",
    "        \n",
    "   \n",
    "        if(fitnessFunction == 'f-measure'):\n",
    "            scores.append(f1_score(y_true=y,y_pred=prediction))\n",
    "        elif(fitnessFunction == 'g-mean'):\n",
    "            gScore = math.sqrt(precision_score(y_true = y, y_pred=prediction)*recall_score(y_true = y, y_pred =prediction ))\n",
    "            scores.append(gScore)\n",
    "        elif(fitnessFunction == 'accuracy'):\n",
    "            scores.append(accuracy_score(y_true = y, y_pred = prediction))\n",
    "        \n",
    "    fitness = [x/sum(scores) for x in scores]\n",
    "    pairedPop = zip(pool, fitness)\n",
    "    rankedPop = sorted(pairedPop, key=itemgetter(-1), reverse = True)\n",
    "    \n",
    "    return rankedPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteratePop(rankedPop):\n",
    "    fitness = [item[-1] for item in rankedPop]\n",
    "    rankedPool = [item[0] for item in rankedPop]\n",
    "   \n",
    "    new_pool = []\n",
    "    new_pool.extend(rankedPool[:int(poolSize/15)])\n",
    "    \n",
    "    while(len(new_pool)<poolSize):\n",
    "        ch1, ch2 = selectFittest(fitness, rankedPool)\n",
    "        ch1, ch2 = breed(ch1, ch2)\n",
    "        \n",
    "        new_pool.append(ch1)\n",
    "        new_pool.append(ch2)\n",
    "    \n",
    "    return new_pool[:poolSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgoFit(datafile,measure):\n",
    "    datafile = pd.read_csv(datafile, dtype={'buggy':np.bool})\n",
    "    X     = datafile.iloc[ : , :-1]\n",
    "    y = datafile['buggy']\n",
    "\n",
    "    pool = np.random.randint(0, 2, (poolSize, X.shape[1]))  \n",
    "    for iteration in range(iterations):\n",
    "#         print iteration\n",
    "        classifier = RandomForestClassifier()\n",
    "        rankedPop = rankPop(pool, X, y, classifier,measure)\n",
    "#         print rankedPop\n",
    "        pool = []\n",
    "        pool = iteratePop(rankedPop)\n",
    "        \n",
    "    best_chromosome = rankPop(pool, X, y, classifier, measure)[0][0]\n",
    "    return best_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'dataset/dataset/'\n",
    "for fileName in os.listdir(directory):\n",
    "    print(fileName)\n",
    "    print(geneticAlgoFit(directory+fileName,'accuracy'))\n",
    "    print(geneticAlgoFit(directory+fileName,'f-measure'))\n",
    "    print(geneticAlgoFit(directory+fileName,'g-mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedFeaturesInEachSoftware = np.array([\n",
    "    [[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1]],\n",
    "    \n",
    "    [[1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1],\n",
    "    [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]],\n",
    "    \n",
    "    [[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]],\n",
    "    \n",
    "    [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1]],\n",
    "    \n",
    "    [[0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0]],\n",
    "    \n",
    "    [[0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1]],\n",
    "    \n",
    "    [[0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
    "    [1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]],\n",
    "    \n",
    "    [[1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]],\n",
    "    \n",
    "    [[1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1]],\n",
    "    \n",
    "    [[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0],\n",
    "    [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]],\n",
    "    \n",
    "    [[0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0]]\n",
    "])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner1 = LogisticRegression(random_state=1)\n",
    "base_learner2 = DecisionTreeClassifier()\n",
    "base_learner3 = GaussianNB()\n",
    "classifier1 = VotingClassifier(estimators=[\n",
    "                                         ('logregression', base_learner1), \n",
    "                                         ('dtree', base_learner2), \n",
    "                                         ('gnb', base_learner3)], \n",
    "                                          voting='soft')  \n",
    "classifier2 = RandomForestClassifier()\n",
    "classifier3 = AdaBoostClassifier(base_estimator = RandomForestClassifier(), n_estimators = 100, learning_rate = 0.5)\n",
    "directory='dataset/dataset'\n",
    "for fileName in os.listdir(directory):\n",
    "    print fileName\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "directory = 'dataset/dataset/'\n",
    "for fileName in os.listdir(directory):\n",
    "    print fileName\n",
    "    data = pd.read_csv(directory+fileName)\n",
    "    X  = data.iloc[ : , :-1]\n",
    "    Y = data.iloc[:,-1]\n",
    "    accuracyFeature = selectedFeaturesInEachSoftware[index][0]\n",
    "    fMeasureFeature = selectedFeaturesInEachSoftware[index][1]\n",
    "    gMeanFeature = selectedFeaturesInEachSoftware[index][2]\n",
    "   \n",
    "    chosen_idx_accuracy = [idx for gene, idx in zip(accuracyFeature, range(X.shape[1])) if gene==1]\n",
    "    chosen_idx_fMeasure = [idx for gene, idx in zip(fMeasureFeature, range(X.shape[1])) if gene==1]\n",
    "    chosen_idx_gMean = [idx for gene, idx in zip(gMeanFeature, range(X.shape[1])) if gene==1]\n",
    "    \n",
    "    for strings in ['Voting','RF','Ada']:\n",
    "        print strings\n",
    "        data['Accuracy_'+strings+'_Pred'],data['Accuracy_'+strings+'_Pred_Prob'] = getPredictions(X.iloc[:,chosen_idx_accuracy],Y,strings)\n",
    "        data['FMeasure_'+strings+'_Pred'],data['FMeasure_'+strings+'_Pred_Prob'] = getPredictions(X.iloc[:,chosen_idx_fMeasure],Y,strings)   \n",
    "        data['GMean_'+strings+'_Pred'],data['GMean_'+strings+'_Pred_Prob'] = getPredictions(X.iloc[:,chosen_idx_gMean],Y,strings)\n",
    "    \n",
    "    print data['GMean_Ada_Pred']\n",
    "    data.to_csv('dataset/annotated/'+fileName,index=False)    \n",
    "    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(X,Y,strings):\n",
    "    \n",
    "    base_learner1 = LogisticRegression(random_state=1)\n",
    "    base_learner2 = DecisionTreeClassifier()\n",
    "    base_learner3 = GaussianNB()\n",
    "\n",
    "    classifier = VotingClassifier(estimators=[\n",
    "                                 ('logregression', base_learner1), \n",
    "                                 ('dtree', base_learner2), \n",
    "                                 ('gnb', base_learner3)], \n",
    "                                  voting='soft')\n",
    "    npoints = X.shape[0]\n",
    "   \n",
    "    if npoints <= 100:\n",
    "        kf = KFold(n_splits = npoints)\n",
    "    else:\n",
    "        kf = KFold(n_splits = 10)\n",
    "        \n",
    "    kf.get_n_splits(X)\n",
    "    train_X = []\n",
    "    train_Y  = []\n",
    "    prediction   = []\n",
    "    predict_prob = []\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        if strings == 'RF':\n",
    "            classifier = RandomForestClassifier()\n",
    "        elif strings == 'Ada':\n",
    "            classifier = AdaBoostClassifier()\n",
    "        else:\n",
    "            classifier = VotingClassifier(estimators=[\n",
    "                                 ('logregression', base_learner1), \n",
    "                                 ('dtree', base_learner2), \n",
    "                                 ('gnb', base_learner3)], \n",
    "                                  voting='soft')\n",
    "        for i in train_index:\n",
    "            train_X.append(X[i])\n",
    "            train_Y.append(Y[i])\n",
    "\n",
    "        classifier.fit(train_X, train_Y)\n",
    "        for j in test_index:\n",
    "            prediction.append(classifier.predict([X[j]])[0])\n",
    "            predict_prob.append(classifier.predict_proba([X[j]])[0][1])\n",
    "        train_X  = []\n",
    "        train_Y  = []\n",
    "\n",
    "    return prediction,predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSelectedFitnessFunction():\n",
    "    for fileName in os.listdir('dataset/annotated'):\n",
    "        selectedFitnessFunction = [] \n",
    "        data = pd.read_csv('dataset/annotated/'+fileName)\n",
    "        \n",
    "        tarr =tt\n",
    "        arr0,arr1 = data[tarr[0]] , data[tarr[1]]\n",
    "        arr2,arr3 = data[tarr[2]] , data[tarr[3]]        \n",
    "        arr4,arr5 = data[tarr[4]] , data[tarr[5]]\n",
    "        arr6,arr7 = data[tarr[6]] , data[tarr[7]]\n",
    "        arr8,arr9 = data[tarr[8]] , data[tarr[9]]\n",
    "        arr10,arr11 = data[tarr[10]] , data[tarr[11]]\n",
    "        arr12,arr13 = data[tarr[12]] , data[tarr[13]]\n",
    "        arr14,arr15 = data[tarr[14]] , data[tarr[15]]\n",
    "        arr16,arr17 = data[tarr[16]] , data[tarr[17]]\n",
    "        \n",
    "        auc_arr = []\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr1))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr3))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr5))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr7))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr9))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr11))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr13))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr15))\n",
    "        auc_arr.append(roc_auc_score(y_true=data['buggy'],y_score=arr17))\n",
    "        \n",
    "        result = np.where(auc_arr == np.amax(auc_arr))\n",
    "        \n",
    "        ans_array  = ['Accuracy_Voting_Pred','FMeasure_Voting_Pred','GMean_Voting_Pred',\n",
    "                      'Accuracy_RF_Pred','FMeasure_RF_Pred','GMean_RF_Pred','Accuracy_Ada_Pred',\n",
    "                     'FMeasure_Ada_Pred','GMean_Ada_Pred']\n",
    "        highest = ans_array[result[0][0]]\n",
    "        \n",
    "        buggy = np.array(data['buggy'])\n",
    "        a = \"\"\n",
    "        b=0\n",
    "        for i in range(len(arr0)):\n",
    "            flag = True\n",
    "            count=0\n",
    "#             print i,\n",
    "            answer = -1\n",
    "            if arr0[i]==buggy[i]:\n",
    "                answer = 0\n",
    "                count+=1\n",
    "                if auc_arr[0]>b:\n",
    "                    a=ans_array[0]\n",
    "                    b=auc_arr[0]\n",
    "                    \n",
    "            if arr2[i]==buggy[i]:\n",
    "                answer = 2\n",
    "                count+=1\n",
    "                if auc_arr[1]>b:\n",
    "                    a=ans_array[1]\n",
    "                    b=auc_arr[1]\n",
    "                    \n",
    "            if arr4[i]==buggy[i]:\n",
    "                answer = 4\n",
    "                count+=1\n",
    "                if auc_arr[2]>b:\n",
    "                    a=ans_array[2]\n",
    "                    b=auc_arr[2]\n",
    "                \n",
    "            if arr6[i]==buggy[i]:\n",
    "                answer = 6\n",
    "                count+=1\n",
    "                if auc_arr[3]>b:\n",
    "                    a=ans_array[3]\n",
    "                    b=auc_arr[3]\n",
    "                \n",
    "            if arr8[i]==buggy[i]:\n",
    "                answer = 8\n",
    "                count+=1\n",
    "                if auc_arr[4]>b:\n",
    "                    a=ans_array[4]\n",
    "                    b=auc_arr[4]\n",
    "                \n",
    "            if arr10[i]==buggy[i]:\n",
    "                answer = 10\n",
    "                count+=1\n",
    "                if auc_arr[5]>b:\n",
    "                    a=ans_array[5]\n",
    "                    b=auc_arr[5]\n",
    "                \n",
    "            if arr12[i]==buggy[i]:\n",
    "                answer = 12\n",
    "                count+=1\n",
    "                if auc_arr[6]>b:\n",
    "                    a=ans_array[6]\n",
    "                    b=auc_arr[6]\n",
    "                \n",
    "            if arr14[i]==buggy[i]:\n",
    "                answer = 14\n",
    "                count+=1\n",
    "                if auc_arr[7]>b:\n",
    "                    a=ans_array[7]\n",
    "                    b=auc_arr[7]\n",
    "                \n",
    "            if arr16[i]==buggy[i]:\n",
    "                answer = 16\n",
    "                count+=1\n",
    "                if auc_arr[8]>b:\n",
    "                    a=ans_array[8]\n",
    "                    b=auc_arr[8]\n",
    "#             print (\"***\",answer)\n",
    "            if count==1 and answer!=-1:\n",
    "                selectedFitnessFunction.append(ans_array[int(answer/2)])\n",
    "            else:\n",
    "                if answer == -1:\n",
    "                    selectedFitnessFunction.append(highest)\n",
    "                else:\n",
    "                    selectedFitnessFunction.append(a)\n",
    "        print (len(selectedFitnessFunction),len(arr0))\n",
    "        data['Function to be selected'] = selectedFitnessFunction\n",
    "#         print data.head()\n",
    "        data.to_csv('dataset/annotated/'+fileName,index=False)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSelectedFitnessFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtreetrain():\n",
    "    directory = 'dataset/dataset/'\n",
    "    annotated_directory = 'dataset/annotated/'\n",
    "    DSF_directory = 'dataset/DSF/'\n",
    "    for projectName in os.listdir(directory):\n",
    "        print(projectName)\n",
    "        projectData = pd.read_csv(directory + projectName)\n",
    "        annotatedData = pd.read_csv(annotated_directory + projectName)\n",
    "        \n",
    "        #X contains software metrics and Y best ensemble selected\n",
    "        X = np.array(projectData.iloc[ : , :-1])\n",
    "        Y = np.array(annotatedData.iloc[ : , -1])\n",
    "#         print (X[0],X[1],Y[0],Y[1])\n",
    "        npoints = X.shape[0]\n",
    "        \n",
    "        if npoints <= 100:\n",
    "            kf = KFold(n_splits = npoints)\n",
    "        else:\n",
    "            kf = KFold(n_splits = 10)\n",
    "        \n",
    "        kf.get_n_splits(X)\n",
    "        train_X = []\n",
    "        train_Y = []\n",
    "        \n",
    "        predictedEnsemble = []\n",
    "        predict_prob      = []\n",
    "        final_prediction  = []  \n",
    "        \n",
    "        prediction_constant = '_Pred'\n",
    "        probab_constant = '_Pred_Prob'\n",
    "        \n",
    "        \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            classifier = DecisionTreeClassifier()\n",
    "            \n",
    "            for i in train_index:\n",
    "                train_X.append(X[i])\n",
    "                train_Y.append(Y[i])\n",
    "            \n",
    "            unique_labels = np.unique(train_Y)\n",
    "            if unique_labels.size == 1:\n",
    "                for j in test_index:\n",
    "                    predictedEnsemble.append(unique_labels[0])\n",
    "                    predict_prob.append(annotatedData.loc[j, unique_labels[0]+\"_Prob\"])\n",
    "                    final_prediction.append(annotatedData.loc[j, (unique_labels[0])])\n",
    "           \n",
    "            else:\n",
    "                classifier.fit(train_X, train_Y)\n",
    "                \n",
    "                for j in test_index:\n",
    "                    predictedBestEnsemble = classifier.predict([X[j]])[0]\n",
    "                    predictedEnsemble.append(predictedBestEnsemble)\n",
    "                    final_prediction.append(annotatedData.loc[j, predictedBestEnsemble])\n",
    "                    \n",
    "            # total probability of available classifiers, i.e the classifiers reported in unique_labels predicting true\n",
    "                    predict_proba_true = 0\n",
    "                    \n",
    "            # probability of classifiers being predicted\n",
    "#                     predict_proba_classifiers = 1#classifier.predict_proba([X[j]])[0]\n",
    "#                     k = 0\n",
    "            # class probabilities are always reported in a sorted by name fashion, i.e AdaBoost, RandomForest, Voting \n",
    "            # np.unique also reports labels in a sorted by name fashion\n",
    "#                     for classifierName in unique_labels:\n",
    "#                         predict_proba_true = \n",
    "#                         k += 1\n",
    "                    predict_prob.append(annotatedData.loc[j, predictedBestEnsemble+\"_Prob\"])\n",
    "                    \n",
    "        annotatedData['PredictedTechnique'] = predictedEnsemble\n",
    "        annotatedData['DSF_Prediction'] = final_prediction\n",
    "        annotatedData['DSF_Pred_Prob'] = predict_prob\n",
    "        annotatedData.to_csv(DSF_directory + projectName, index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svctrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceMeasuresDSF():\n",
    "    DSFdirectory = 'dataset/finalResults/'\n",
    "    projectMetrics = []\n",
    "    index = 0\n",
    "    projectMetrics = pd.DataFrame(projectMetrics,\n",
    "                                    columns = ['Project','Precision', 'Recall', 'Auc_Score', 'Accuracy', 'Fmeasure', 'GMean'])\n",
    "    for projectName in os.listdir(DSFdirectory):\n",
    "        print (projectName)\n",
    "        project = pd.read_csv(DSFdirectory + projectName)\n",
    "        projectData = project.as_matrix(columns=[\n",
    "                                         'DSF_Prediction',\n",
    "                                         'DSF_Pred_Prob',\n",
    "                                         'buggy'])\n",
    "      \n",
    "        row = []\n",
    "        row.append(projectName)\n",
    "        row.extend(computePerformanceMeasures(project['DSF_Prediction'], \n",
    "                                                         project['buggy'], \n",
    "                                                         project['DSF_Pred_Prob']))\n",
    "        projectMetrics.loc[index] = row\n",
    "        index = index + 1\n",
    "  \n",
    "    print(projectMetrics)\n",
    "    projectMetrics.to_csv('dataset/' + 'results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computePerformanceMeasuresDSF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceMeasures(predictions, labels, prediction_probability):\n",
    "    \n",
    "    precision = precision_score(y_true = labels, y_pred = predictions)\n",
    "    recall    = recall_score(y_true = labels, y_pred = predictions)\n",
    "    roc_score = roc_auc_score(labels, prediction_probability)\n",
    "    accuracy  = accuracy_score(y_true = labels, y_pred = predictions)\n",
    "    f_measure = 2*(precision * recall)/float(precision + recall) \n",
    "    g_mean = math.sqrt(precision * recall)\n",
    "    \n",
    "    metrics = [precision, recall, roc_score, accuracy, f_measure, g_mean]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceMeasuresForTechniques():\n",
    "    annotated_directory = 'dataset/annotated/'\n",
    "    resultsFile = open('dataset/performanceMeasures.csv','w+')\n",
    "    for projectName in os.listdir(annotated_directory):\n",
    "        project = pd.read_csv(annotated_directory+projectName)\n",
    "        for techniques in ['Accuracy_Voting','FMeasure_Voting','GMean_Voting','Accuracy_RF','FMeasure_RF','GMean_RF','Accuracy_Ada','FMeasure_Ada','GMean_Ada']:\n",
    "            prediction = project[techniques+'_Pred']\n",
    "            labels     = project['buggy']\n",
    "            prediction_probability = project[techniques+'_Pred_Prob']\n",
    "            measures = (','.join(str(x) for x in computePerformanceMeasures(prediction,labels,prediction_probability))+'\\n')\n",
    "            resultsFile.write(str(projectName)+','+techniques+','+measures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computePerformanceMeasuresForTechniques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strings in ['Voting','RF','Ada']:\n",
    "        print strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for fileName in os.listdir('dataset/annotated'):\n",
    "        np.where(arr == 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in os.listdir('dataset/DSF'):\n",
    "    fil = pd.read_csv('dataset/DSF/'+fileName)\n",
    "    fil=fil.drop(columns=tt)\n",
    "    fil.to_csv('dataset/finalResults/'+fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = pd.read_csv('dataset/DSF/camel-1.6.csv') \n",
    "tt=fil.columns.values\n",
    "tt= (tt[21:39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
